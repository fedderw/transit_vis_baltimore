{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization/Analysis of Local GTFS-RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import branca.colormap as cm\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from folium.plugins import HeatMapWithTime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import seaborn as sns\n",
    "\n",
    "TZ = pytz.timezone('America/Los_Angeles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corridor_segments = {\n",
    "    0: {\n",
    "        2749,\n",
    "        2751,\n",
    "        2752,\n",
    "        2753,\n",
    "        2754,\n",
    "        2755,\n",
    "        2756,\n",
    "        2757\n",
    "    },\n",
    "    1: {\n",
    "        12200,\n",
    "        12201,\n",
    "        12202,\n",
    "        12203,\n",
    "        12204\n",
    "    },\n",
    "    2: {\n",
    "        13532,\n",
    "        13533,\n",
    "        13534,\n",
    "        13535,\n",
    "        13536\n",
    "    },\n",
    "    3: {\n",
    "        14585,\n",
    "        14586,\n",
    "        14587,\n",
    "        14589,\n",
    "        14590,\n",
    "        14591,\n",
    "        14243\n",
    "    },\n",
    "    4: {\n",
    "        8510,\n",
    "        8511,\n",
    "        8512,\n",
    "        8513,\n",
    "        8514\n",
    "    },\n",
    "    5: {\n",
    "        13221,\n",
    "        13220,\n",
    "        13219,\n",
    "        13218,\n",
    "        13217\n",
    "    },\n",
    "    6: {\n",
    "        18045,\n",
    "        18046,\n",
    "        18047,\n",
    "        18048,\n",
    "        18049\n",
    "    },\n",
    "    7: {\n",
    "        19235,\n",
    "        19234,\n",
    "        11333,\n",
    "        11331,\n",
    "        11330,\n",
    "        11329,\n",
    "        19212\n",
    "    },\n",
    "    8: {\n",
    "        12369,\n",
    "        12366,\n",
    "        12365,\n",
    "        12364,\n",
    "        12363\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the Local Summarize_RDS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location for the local data\n",
    "path = './transit_vis/data/to_upload'\n",
    "files = os.listdir(path)\n",
    "\n",
    "# Join all the data which is saved in different csv for each day\n",
    "# frames = [pd.read_csv(f\"{path}/{filename}\", dtype={'trip_short_name': str, 'route_short_name': str}) for filename in files[0:30]]\n",
    "# all_data = pd.concat(frames)\n",
    "# all_data.to_csv(f\"{path}/../all_data.csv\")\n",
    "# all_data.head()\n",
    "\n",
    "# If already processed, load the data here and comment out above\n",
    "all_data = pd.read_csv(f\"{path}/../all_data.csv\", dtype={'trip_short_name': str, 'route_short_name': str})\n",
    "all_data.head()\n",
    "\n",
    "# Rename and style\n",
    "all_data['speed_m_s'] = all_data['avg_speed_m_s']\n",
    "#all_data = all_data[all_data['at_stop'] == True]\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Top 10/Top Random Coaches that Spend Most Time in Corridors, and Avg Unique Corridor Traversals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to period of interest\n",
    "# start_time = 1607072400 # 12/4/20 1AM\n",
    "# end_time = 1608282000 # 12/18/20 1AM\n",
    "start_time = 1607518800 # 12/9/20 5AM\n",
    "end_time = 1607583600 # 12/9/20 11PM\n",
    "all_data = all_data.loc[(all_data['locationtime'] > start_time) & (all_data['locationtime'] < end_time)]\n",
    "\n",
    "# Get list of all segments in our corridors\n",
    "segments_dict = list(corridor_segments.values())\n",
    "all_corridor_segments = []\n",
    "for item in segments_dict:\n",
    "    for seg in item:\n",
    "        all_corridor_segments.append(seg)\n",
    "\n",
    "# Filter to only tracked locations in our corridors\n",
    "data = all_data.loc[all_data['seg_compkey'].isin(all_corridor_segments)]\n",
    "del all_data\n",
    "\n",
    "#data.to_csv(\"for_borna.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average number of traversals per corridor\n",
    "# Want count of unique trip ids for each segment id\n",
    "traversal_data = data.groupby(['seg_compkey']).nunique('tripid').reset_index()\n",
    "for corridor in corridor_segments:\n",
    "    corridor_data = traversal_data.loc[traversal_data['seg_compkey'].isin(list(corridor_segments[corridor]))]\n",
    "    print(corridor_data['lat'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top ten vehicles with most tracked locations\n",
    "vehicle_counts = data.groupby('vehicleid').count().reset_index()[['vehicleid', 'lat']]\n",
    "vehicle_list = vehicle_counts.sort_values('lat', ascending=False)\n",
    "vehicle_list = vehicle_list.iloc[:10,:]\n",
    "vehicle_list = vehicle_list['vehicleid'].values\n",
    "corridor_data_10 = data[data['vehicleid'].isin(vehicle_list)]\n",
    "print(f\"Number of tracks for best 10 routes: {len(corridor_data_10)}\")\n",
    "\n",
    "# Get the data corresponding to ten random vehicles\n",
    "vehicle_list = vehicle_counts.sample(10)\n",
    "vehicle_list = vehicle_list.sort_values('lat', ascending=False)\n",
    "vehicle_list = vehicle_list.iloc[0:1,:]\n",
    "vehicle_list = vehicle_list['vehicleid'].values\n",
    "corridor_data_rand = data[data['vehicleid'].isin(vehicle_list)]\n",
    "print(f\"Number of tracks for best random route: {len(corridor_data_rand)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Densities by Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000 iterations for random 10 vehicle ids from past two weeks\n",
    "best_route_name = []\n",
    "best_route_count = []\n",
    "for i in range(0, 1000):\n",
    "    sample = vehicle_counts.sample(10)\n",
    "    sample = sample.sort_values('lat', ascending=False)\n",
    "    sample = sample.iloc[0:1,:]\n",
    "    best_route_name.append(sample['vehicleid'].values[0])\n",
    "    best_route_count.append(sample['lat'].values[0])\n",
    "\n",
    "# The top 20 vehicles\n",
    "top_route_name = []\n",
    "top_route_count = []\n",
    "sample = vehicle_counts.sort_values('lat', ascending=False)\n",
    "sample = sample.iloc[:10,:]\n",
    "top_route_name.append(sample['vehicleid'].values)\n",
    "top_route_count.append(sample['lat'].values)\n",
    "top_route_count = list(top_route_count[0])\n",
    "\n",
    "# All vehicles\n",
    "all_route_count = list(vehicle_counts['lat'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of number of tracks across network\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "sns.kdeplot(best_route_count, bw_adjust=1)\n",
    "sns.kdeplot(top_route_count, bw_adjust=1)\n",
    "sns.kdeplot(all_route_count, bw_adjust=1)\n",
    "fig.legend(labels=['Top Sampled Count','Top Un-Sampled Count','All Counts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Spatial Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(corridor_data_rand['route_short_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the map\n",
    "f_map = folium.Map(\n",
    "    location=[47.606209, -122.332069],\n",
    "    zoom_start=11,\n",
    "    prefer_canvas=True)\n",
    "\n",
    "# Create and add layer for all the sampled coordinate data\n",
    "# lats = sampled['lat'].tolist()\n",
    "# lons = sampled['lon'].tolist()\n",
    "# points = zip(lats, lons)\n",
    "# points = list(points)\n",
    "# HeatMap(\n",
    "#     data=points,\n",
    "#     name='Points',\n",
    "#     radius=8,\n",
    "#     min_opacity=0.2\n",
    "# ).add_to(f_map)\n",
    "\n",
    "# Create and add layer for all the sampled coordinate data in our corridors\n",
    "lats = corridor_data_rand['lat'].tolist()\n",
    "lons = corridor_data_rand['lon'].tolist()\n",
    "points = zip(lats, lons)\n",
    "points = list(points)\n",
    "HeatMap(\n",
    "    data=points,\n",
    "    name='Points',\n",
    "    radius=8,\n",
    "    min_opacity=0.2\n",
    ").add_to(f_map)\n",
    "\n",
    "folium.LayerControl().add_to(f_map)\n",
    "\n",
    "# Save map and plot in notebook\n",
    "f_map.save(f\"./local_sampled_map.html\")\n",
    "f_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
